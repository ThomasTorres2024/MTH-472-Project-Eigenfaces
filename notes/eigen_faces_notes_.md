# Overview

#### Abstract Summary
- Eigen faces is a method we can use facial recognition to determine a person out of a crowd, it's fairly quick
- Faces are assumed to be 2d, works out fairly well 
- We project a face image onto a space that has a lot of the different variations of faces
- Significant features are eigenfaces, they are the eigen vectors/principal components of the set of faces
- We can project onto the feature space, and calculate a weighted sum of these components, which allows us to determine the individual from the dataset 
- can learn and recognize new faces unsupervised 

# Background
Eigenfaces leverage [[Principal Component Analysis (PCA)]] in order to identify a face from a given dataset of faces in a computationally efficient manner. Eigenfaces can add new members to their overall dataset, and identify new faces added to the set.

Previous algorithms existed which already were somewhat successful at facial recognition, though these focused primarily on recognizing features of faces like eyes, nose, mouth, head outline, etc, and then trying to find relationship between these elements, however this particular model was fragile.

Many models before Eigenfaces ignored the key problem of asking what aspects of the face are actually important for identification? 
The eigenface approach tries to go about this through an "Information Theory Approach", where we want to extract relevant information in a face, encode it, and compare different face encodings.

This essentially means applying PCA to find the principal components and thereby most important characteristics in the face. Other approaches looked at specific features that would be important to humans for identification, like nose, face, ear structure but not necessarily other structure. 

---
# Algorithm Overview

We begin by taking the dataset of faces, $D$, and breaks the dataset into a smaller set of characteristic images. These smaller characteristic images are eigenfaces, and are thought of as the [[Principal Component]]s of the training set of face images. 

A new image is classified by projecting it down into the "face space", and classifying the face by comparing its position with the face of already known persons. This is am important feature, especially if we want to recognize people that we already have seen within our dataset. 

The training set constrains itself to a limited set of angles of an individual, a $45^\degree$ angle, a profile view, and a straight on view, which overall allows the algorithm to classify faces from many different angles.  

Each image in our dataset is assumed square, black-white, and of size $n \times n$. We can represent each image as a vector residing in $\mathbb{R}^{n^2}$. Note that this a very high dimensional space even if the image is relatively small. A $16 \times 16$ image resides in $\mathbb{R}^{256}$. Let each image in the dataset be represented by $\vec{x_{i}}$. 

Given $D=\{\vec{x_{1}},\vec{x_{2}},\cdots,\vec{x_{m}} \}$ where each $\vec{x_{i}} \in \mathbb{R}^{n^2}$. We begin by performing PCA, which means determining the [[Covariance Matrix]] of $D$, and then subtracting the mean vector, $\vec{\mu}= \frac{1}{m} \sum_{i}^m \vec{x_{i}}$.  

The covariance matrix of $D$,  is a [[Symmetric Matrix]] and is thereby [[unitarily diagonalizable]], and so it has a non-unique factorization as:
$$C=X\Lambda X^{T}$$
In the eigenface algorithm, we particularly choose to order $\Lambda$ by descending eigen values such that the highest principal component is first, and we organize each eigen vector as such. We can think of the [[eigen vectors]] as some feature between the images which has its own respective weight of its corresponding eigen value. We can actually view some of the images generated by this procedure, since the generated eigen vector is another 256 dimensional entry.  Eigenfaces have a very ghostly appearance to them. 

Because we have a full set of eigenvectors, the set of all images living in $\mathbb{R}^{n^2}$ can be represented as a linear combination of the eigen vectors from $X$. We can also perform a truncation to only consider the best eigen vectors, that is eigen vectors where for $\lambda > \epsilon_{threshold}$, we know that the corresponding eigen vector is more "important". This is similar to [[Truncated SVD]]. 

This particular idea for representing faces with [[Principal Component Analysis (PCA)]] comes from 2 other authors, Sirovich and Kirby, that made a method to efficiently represent face pictures, where essentially you could store some eigen pictures from a set of images (I'm pretty sure what they mean by this is much like the images here, we can get some eigen-vector representation of a face that spans the facespace, and then can find some appropriate linear combination such that any vector in the facespace is something we can represent). 

If we think about the size of these images and the amount of info we need to store them, any particular face is now storable as a few coefficients representing a sum over the eigenfaces.  

### Initialization Algorithm 
From this we can more formally describe the initialization of the facespace and eigenfaces. We run this process before our first training, or whenever we have spare time computationally. After we add in more faces, we want to add them to the existing set and train it. 

1. Get an initial set of face images, the training set 
2. Get the eigenfaces from the set with the highest corresponding [[eigen value]]s, these $M$ images span the "face space". As we encounter new faces, eigenfaces can be updated or recalculated. 
3. For every image in our Dataset, we can project it onto the facespace to determine the set of weights for each person to represent all (technically not all since $M$ is not necessarily all of the eigen-vectors) possible faces 

### Facial Recognition Step 
We can recognize new faces that are in our dataset by performing the following procedure. Note, it must be the case that our model has already been initialized. 
1. Take a new image, and calculate its weights by projecting the image onto each of the eigen faces 
2. Determine if the image is a face, which we do by checking to see if the image is close enough to the face space 
3. If the face can be determined to be a face, classify the weight pattern as a person that is known or unknown 
4. (Optional) Update Eigenfaces/Weight Patterns
5. (Optional) if we see the same unknown face multiple times, find its weight pattern and incorporate it into the known faces 

---
# Calculation of Eigenfaces 